<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>On OpenLLM Leaderboard | Mohammad Arvan</title> <meta name="author" content="Mohammad Arvan"> <meta name="description" content="Technical review of the latest changes in the OpenLLM leaderboard"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mo-arvan.github.io/blog/2024/on-openllm-leaderboard/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "On OpenLLM Leaderboard",
      "description": "Technical review of the latest changes in the OpenLLM leaderboard",
      "published": "July 1, 2024",
      "authors": [
        {
          "author": "Mohammad Arvan",
          "authorURL": "https://mo-arvan.github.io/",
          "affiliations": [
            {
              "name": "Department of Computer Science, University of Illinois at Chicago",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Mohammad </span>Arvan</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/personal/">personal</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item"> <a class="nav-link" href="https://mo-arvan.github.io/assets/pdf/Mohammad_Arvan_CV.pdf"> CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>On OpenLLM Leaderboard</h1> <p>Technical review of the latest changes in the OpenLLM leaderboard</p> </d-title><d-byline></d-byline><d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#summary-of-changes">Summary of Changes</a></div> <div><a href="#technical-review">Technical Review</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>The OpenLLM leaderboard is a collection of benchmarks for large language models. Unlike numbers reported in marketing materials, the results on the leaderboard are reproducible and can be verified by anyone. This leaderboard is managed by the Hugging Face team and is based on the Harness (lm-eval) package from EleutherAI. Overall, the leaderboard is a valuable resource for the community to compare different models and track progress in the field. Recently, the Hugging Face team announced several changes to the leaderboard. In this post, I will review these changes and discuss their implications.</p> <h2 id="summary-of-changes">Summary of Changes</h2> <p>In their blog post, the Hugging Face team raise several issues with this leaderboard. Firstly, they highlight the problem of saturation, where performance on certain benchmarks reaches human level.</p> <p>Moreover, they suggest that certain models are showing signs of data contamination. This is a serious issue that can lead to misleading results and conclusions. Without a clear chain of custody for the data used in training, it’s difficult to confirm data contamination in a model.</p> <p>Finally, they point out some of the recent investigations into issues in datasets quality, particularly MMLU-Redux and MMLU-Pro.</p> <p>To address these issues, they are rebooting the leaderboard with newly released benchmarks and high-quality datasets. Additionally, they are introducing a normalization step, setting a random baseline as 0 and the maximum score as 100. They also updated the Harness (lm-eval) package from EleutherAI to its latest version and added support for LoRA finetuning. They claim these changes should enhance the reproducibility of the results.</p> <p>To combat data contamination in submitted models, they are introducing a maintainer’s highlight. They will handpick models released by reputable organizations that have been thoroughly vetted. This list will remain open and evolve based on community feedback and their own observations.</p> <p>Lastly, they are introducing a voting mechanism for running new models on the leaderboard. This aims to address the issue of submission spamming, where multiple variants of a model are submitted to see which performs best. They hope the voting mechanism will mitigate this problem. Additionally, there are user interface improvements thanks to the work of the Gradio team.</p> <h2 id="technical-review">Technical Review</h2> <p>I find all these changes to be positive steps towards more reliable and reproducible benchmarks. While the maintainer’s highlight section could introduce biases from the Hugging Face team, their language suggests they are open to feedback and aim to be community-driven. Given the challenges of identifying models trained on contaminated data, I believe this is a reasonable compromise. However, I still think the evaluation process could be improved.</p> <p>My primary concern with this leaderboard is the lack of effort to account for stochasticity in the evaluation process. Although training neural networks involves sources of randomness such as weight initialization, data order, and dropout, once trained, these models become deterministic. They output a probability distribution for each class they are trained on, and in the case of language models, the classes are the tokens in the vocabulary. Greedy selection of the highest probability results in generated text that often appears “robotic.” To address this, the common approach is to use sampling with an adjusted temperature for the softmax function, introducing randomness in the generation process. Given that two datasets, IFEval and MATH, utilize text generation, it is important to account for this variability and report a set of results for each model.</p> <p>Regarding other tasks, it seems that lm-harness is moving towards a standardized template and format for all model evaluations. While this is systematic, it might backfire because in real-world use cases, inputs might not always be in the same format. This could result in models that are not robust to different inputs. Therefore, I believe evaluating the models with various input formats and reporting a set of results would provide a more accurate picture of the models’ performance.</p> <p>Both of these changes would indeed necessitate additional computational resources and time. It’s possible that lm-eval already addresses such variability, although the blog post does not mention it explicitly. In my next post, I will delve deeper into the source code of lm-eval and see if these concerns are already addressed.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Mohammad Arvan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 23, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>